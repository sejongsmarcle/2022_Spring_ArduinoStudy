1주차 미션. Teachable Machine 으로 인공지능 맛보기.
===
-------------
>_1. 사진 고르기_  
------------- 
>평소에 즐겨하던 게임 캐릭터 3개를 골라서 판별해보기로 했다. 인터넷으로 캐릭터의 일러스트를 검색해서 파일을 업로드 한 뒤 학습시켜보았다.   
>실험체가 될 캐릭터들의 이름은 각각 중운, 아야카, 종려.
>![image](https://user-images.githubusercontent.com/67413252/160266207-d40166eb-c5f5-4ac9-8d6e-abfb74d903ff.png)
-------------
>_2. 문제가 생겼다._
-------------
>왜 이러는 걸까요?
>![image](https://user-images.githubusercontent.com/67413252/160266074-78c979b8-145e-445e-9955-514b38c29cc5.png)
>Device에서 Pile로 입력을 전환해 주니 해결됨.
>![image](https://user-images.githubusercontent.com/67413252/160266097-270af824-a4cc-408e-a6f7-8a1fc31f5336.png)
>그런데 결과가 이상하게 나온다...?
>![image](https://user-images.githubusercontent.com/67413252/160266132-0b28d115-62d3-4c2f-80ae-5dfd8a96fa2e.png)
>기기에 하자(?)가 있어서 표준모델로 전환 후 다시 만들어야 할 것 같다.(한 4년은 쓴 노트북이라 그런가...?)
--------------
>_3. 결국 완성...?_
--------------
>다시 만들어서 결과를 확인해 보았다.
>![image](https://user-images.githubusercontent.com/67413252/160266352-46a11153-8936-4f69-bbb6-07074170e1df.png)
>정상적으로 나옴.   
>그런데....
>![image](https://user-images.githubusercontent.com/67413252/160266393-3c653ea8-16b8-4cb4-a310-77649b3de872.png)
>![image](https://user-images.githubusercontent.com/67413252/160266418-f3b338aa-1f89-4b7c-8b78-725c057368a8.png)
>![image](https://user-images.githubusercontent.com/67413252/160266432-4ca79fd4-8f0b-477b-977e-b1bfea844096.png)
>같은 푸른색 계열이라 그런지 아야카와 중운은 좀 오락가락함. 샘플의 이미지와 비슷하면 잘 인식하지만 조금 차이나는 이미지를 주면 인식을 못함.
--------------
>_4. epoch와 batch size에 대하여_
--------------
>One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE   
>(한 번의 epoch는 인공 신경망에서 전체 데이터 셋에 대해 forward pass/backward pass 과정을 거친 것을 말함. 즉, 전체 데이터 셋에 대해 한 번 학습을 완료한 상태) 
▶ 신경망에서 사용되는 역전파 알고리즘(backpropagation algorithm)은 파라미터를 사용하여 입력부터 출력까지의 각 계층의 weight를 계산하는 과정을 거치는 순방향 패스(forward pass), forward pass를 반대로 거슬러 올라가며 다시 한 번 계산 과정을 거처 기존의 weight를 수정하는 역방향 패스(backward pass)로 나뉩니다. 이 전체 데이터 셋에 대해 해당 과정(forward pass + backward pass)이 완료되면 한 번의 epoch가 진행됐다고 볼 수 있습니다.   
>Batch size is total number of training examples present in a single batch.   
>Iteration is the number of passes to complete one epoch.   
>(batch size는 한 번의 batch마다 주는 데이터 샘플의 size. 여기서 batch는 나눠진 데이터 셋을 뜻하며 iteration는 epoch를 나누어서 실행하는 횟수라고 생각하면 됨.)
▶ 메모리의 한계와 속도 저하 때문에 대부분의 경우에는 한 번의 epoch에서 모든 데이터를 한꺼번에 집어넣을 수는 없습니다. 그래서 데이터를 나누어서 주게 되는데 이때 몇 번 나누어서 주는가를 iteration, 각 iteration마다 주는 데이터 사이즈를 batch size라고 합니다.
>참고 자료: https://m.blog.naver.com/qbxlvnf11/221449297033
--------------
>_5. 추가 실험_
--------------
>epoch를 늘려서 다시 학습시키고 본 결과
>![image](https://user-images.githubusercontent.com/67413252/160266584-0540adf1-2c31-493b-93a0-cdd634dba288.png)
>아마 샘플의 문제인듯(샘플의 수 부족, 일원적인 샘플 등등의 이유인듯)
--------------
>_6. 결론_
--------------
>생각보단 분류가 잘 되지 않아 조금 실망하기는 했지만... 그래도 이렇게 간단하게라도 직접 인공지능을 만들어보고 체험해 본다는 경험 자체가 귀중한 것 같다.   
>실제 코드   
>
    Teachable Machine Image Model
    Start
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script> <script type="text/javascript"> // More API functions here: // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "./my_model/";

    let model, webcam, labelContainer, maxPredictions;

    // Load the image model and setup the webcam
    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
    }
    ```
