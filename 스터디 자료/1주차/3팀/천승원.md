1주차 미션. Teachable Machine 으로 인공지능 맛보기.
===
-------------
>_1. 사진 고르기_  
------------- 
>평소에 즐겨하던 게임 캐릭터 3개를 골라서 판별해보기로 했다. 인터넷으로 캐릭터의 일러스트를 검색해서 파일을 업로드 한 뒤 학습시켜보았다.   
>실험체가 될 캐릭터들의 이름은 각각 중운, 아야카, 종려.
>![image](https://user-images.githubusercontent.com/67413252/160266207-d40166eb-c5f5-4ac9-8d6e-abfb74d903ff.png)
-------------
>_2. 문제가 생겼다._
-------------
>왜 이러는 걸까요?
>![image](https://user-images.githubusercontent.com/67413252/160266074-78c979b8-145e-445e-9955-514b38c29cc5.png)
>Device에서 Pile로 입력을 전환해 주니 해결됨.
>![image](https://user-images.githubusercontent.com/67413252/160266097-270af824-a4cc-408e-a6f7-8a1fc31f5336.png)
>그런데 결과가 이상하게 나온다...?
>![image](https://user-images.githubusercontent.com/67413252/160266132-0b28d115-62d3-4c2f-80ae-5dfd8a96fa2e.png)
>기기에 하자(?)가 있어서 표준모델로 전환 후 다시 만들어야 할 것 같다.(한 4년은 쓴 노트북이라 그런가...?)
--------------
>_3. 결국 완성...?_
--------------
>다시 만들어서 결과를 확인해 보았다.
>![image](https://user-images.githubusercontent.com/67413252/160266352-46a11153-8936-4f69-bbb6-07074170e1df.png)
>정상적으로 나옴.   
>그런데....
>![image](https://user-images.githubusercontent.com/67413252/160266393-3c653ea8-16b8-4cb4-a310-77649b3de872.png)
>![image](https://user-images.githubusercontent.com/67413252/160266418-f3b338aa-1f89-4b7c-8b78-725c057368a8.png)
>![image](https://user-images.githubusercontent.com/67413252/160266432-4ca79fd4-8f0b-477b-977e-b1bfea844096.png)
>같은 푸른색 계열이라 그런지 아야카와 중운은 좀 오락가락함. 샘플의 이미지와 비슷하면 잘 인식하지만 조금 차이나는 이미지를 주면 인식을 못함.
--------------
>_4. 추가 실험_
--------------
>epoch를 늘려서 다시 학습시키고 본 결과
>![image](https://user-images.githubusercontent.com/67413252/160266584-0540adf1-2c31-493b-93a0-cdd634dba288.png)
>아마 샘플의 문제인듯(샘플의 수 부족, 샘플이 너무 일원적임 등등의 이유인듯)
--------------
>_5. 결론_
--------------
>그래도 재밌었다.   
>실제 코드 내용   
>
    ```java

    // the link to your model provided by Teachable Machine export panel
    const URL = "./my_model/";

    let model, webcam, labelContainer, maxPredictions;

    // Load the image model and setup the webcam
    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
    }
    ```
